---
title: This Week I Learned - Week 43 2021
slug: til43
date: 2021-10-31 21:30:02 +0100
publications_src: content/til.bib
--- 

So I am now done with my master thesis, and after a week on holiday - sailing in Denmark - I am more in the mood to share what I recently learned

## Effect of the Week - Hyperactive intent presumption
Hyperactive intent presumption describes the presumption that we as individuals can change the world. The presumption has two parts grounded in psychology: The *focusing illusion*, where we systematically overestimate the importance of our doing, and the *intentional stance*, where we suspect intention - no matter whether there is the intention behind it or not.
With our hominid ancestry with hyperactive intentionality, this is still is hardwired into our brains today. Therefore, we see intention and acting agents even where there is none. This fuels conspiracy theory, dictatorship and sometimes restricts joint responsible action like on the topic of climate change. Individual consumption plays a role but is not as significant as you might think. The richest 10% emit about half the greenhouse gases, the richest 1% emit 15% ([Source](https://www.treehugger.com/personal-consumption-richest-one-percent-study-5204287)). But let's not dive into that topic too much, there are surely others who can better argue against or for this.

## AI 
I am thinking about AI and Food/Recipes a lot. I was at the ZKM Museum in Karlsruhe and enjoyed the exhibition [BarabásiLab. Hidden Patterns](https://zkm.de/de/ausstellung/2021/05/barabasilab-hidden-patterns) quite a lot. I found particularly interesting the part with Flavor Networks [@@ahn2011flavor], where the mapping of ingredient connections in recipes of different locations tells an astonishing story. I was therefore wondering if all of the data that is already available in digital recipe form can be used to train models, that then know what we like in food or not.  [@Salvador2019inversecooking] from Facebook even trained AI models to generate natural text only from food images. You can input an image of your dish and the model predicts the ingredients and how to prepare the plate in front of you.
So what happens if we get more creative by utilizing the inherent knowledge of our societies about flavors, tastes, and good food often with a history at its core. 

My grudge against overusing the term *Artificial Intelligence* instead of e.g. Machine Learning seems to be shared by [others](https://spectrum.ieee.org/stop-calling-everything-ai-machinelearning-pioneer-says)
*“For the foreseeable future, computers will not be able to match humans in their ability to reason abstractly about real-world situations, we will need well-thought-out interactions of humans and computers to solve our most pressing problems. We need to understand that the intelligent behavior of large-scale systems arises as much from the interactions among agents as from the intelligence of individual agents."* 
An Artificial *Intelligence* will not suddenly happen, and the current system is not intelligent as it can solve a human range of problems. There are specified areas where Machine or Deep Learning has reached human-level, but across the tasks (trained) humans still outperform any artificial system.
 

Image Inpainting (Removing Parts of the Image) is so good with the [latest publications](https://github.com/saic-mdal/lama) that it is can be used by everyone.
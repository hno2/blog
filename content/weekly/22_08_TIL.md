title: Improvisation for Business
date: 2020-12-02
status: draft
---


Afraid about Deepfakes? Ask the person to [turn their head sideways](https://metaphysic.ai/to-uncover-a-deepfake-video-call-ask-the-caller-to-turn-sideways/). 
There are two good reasons for this 
1. While Deepfakes are trained on massive amounts of (celebrity) photos from the internet they seldom include profile views. Therefore the face transfer quality is massivly worse in this view. In general very little 90 degree profile pictures are available as stock photos (wonder why: pictures in profile do not show emotion as well)
2. Deepfakes relie on Landmark Detection to create a model of the face in space from landmarks as eyes, mouth, nose and more. In a profile view more than half of the landmarks are hidden or very close together, therefore it is very hard to determine the face positon in the 90 Deg Profile View.


Do not see pretrained Foundation Models like GPT3, DALLE or PALM as "trained like a children". Children get multimodal feedback also including supervised not only self-supervised feedback. Instead RAPHAËL MILLIÈRE argues to call what these models do Artificial Mimicry, it is clear we moved from stochastic parrots (repeating previously known information at random/at probability) to stochastic chameleons, which blend in with their - in this context human context - to provide what we expect.
[Source](https://nautil.us/moving-beyond-mimicry-in-artificial-intelligence-21015/)
 these models 


 [Researchers from Stanford University](https://www.pnas.org/doi/10.1073/pnas.2123433119) used few-shot learning to generate program code (via OpenAI Codex) that solves MIT-level Math Problems. The rephrase the prompt from the original math problem to prompting for the model to write a program thats solves that. Using this articially generated code a pipeline is built, which calculates the results. With this they increase their curren state of the art on the MATH benchmark from 8.8 % to 81.


Humans are flexible by natural selection, only those who learned fast and adapted survived. But this learning skills comes with the pitfall that we humans are born without little preconceived ideas how stuff works. This becomes especially true we talk about own experiences. Every one seems to construct his or her own reality, that makes you wonder wether you were at the same party or not. The human brain is made to fill the gaps between actual key memories with a storyline fitting best to ones previos experiences. Hebbian Learning is the biological concept why. Speaking on a very high level, neuronal activation loves to take the beaten path, as neurons that wire together (connection), fire together. So any reality we percieve is a construct, a personal version of reality. You cannot escape this, but the more different real-world experiences you are been exposed to, the less implicit bias your construct of a reality. 

Filled with expirienes

> You might think of implicit bias as the result of an over-adaptation that occurs when a brain becomes entrenched in an environment that is sufficiently narrower than the one you would like to operate in. And being aware of this kind of over-adaptation seems even more relevant as we begin to emerge from our narrower-than-usual pandemic isolation bubbles. To correct the shortcuts in our brains, we can expose ourselves to diverse, real-world experiences and allow narratives told from different points of view to shape us. If we can become more intentional about what kinds of experiences we feed our brains, we can help to shape the ways our future selves adapt to the world.


Mom, we have DALLE at home. Almost it the github project [Stable Diffussion](https://github.com/CompVis/stable-diffusion) looks like a good start 
